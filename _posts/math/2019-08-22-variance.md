---
layout: post
title:  "方差"
date:   2019-08-22 08:14:54
categories: math
tags: math 
excerpt: 方差，协方差等等
mathjax: 1
thumbnail: "assets/img/post/math.jpg"
feature-img: "assets/img/post/math.jpg"
---

* content
{:toc}
> 记录方差和协方差的定义和意义，最重要的是记录具体是怎么计算的，可以有一个感性的认识
>
> 总得来说，方差描述了数据（序列）自身的离散程度，协方差描述了序列同向变化的程度。

## 一、方差

### 1、简单定义

> 统计中的方差（样本方差）是每个样本值与全体样本值的**平均数之差**的平方值的平均数。

### 2、实际意义

> 在概率论和数理统计中，方差（英文Variance）用来度量随机变量和其数学期望（即均值）之间的**偏离程度**。数值越大，偏离程度越大

### 3、公式定义

**在统计描述中**，方差用来计算每一个变量（观察值）与总体均数之间的差异。为避免出现离均差总和为零，离均差平方和受样本含量的影响，统计学采用平均离均差平方和来描述变量的变异程度。

总体方差计算公式：

<br>
$$
\sigma^2=\frac{\sum(X-\mu)^2}{N}
\tag{1}
$$
<br>

其中：$\sigma^2$ 为总体方差，$X$为变量，$\mu$为总体均值，$N$为总体例数。

> $N$其作用为将计算得到的累积偏差进行平均，从而消除数据集大小对计算数据离散程度所产生的影响。

**实际工作中**，总体均数难以得到时，应用样本统计量代替总体参数，经校正后，

样本方差计算公式：

<br>
$$
S^2=\frac{\sum(X-\overline X)^2}{n-1}
\tag{2}
$$
<br>

其中：$S^2$ 为总体方差，$X$为变量，$\overline X$为样本均值，$n$为样本例数。

---

**在概率分布中**，设X为服从分布F的随机变量， 如果E[X]是随机变数X的期望值（平均数$\mu=E[X]$）
随机变量$X$或者分布$F$的方差为：

<br>
$$
Var(X)=E[(X-\mu)^2]
\tag{3}
$$
<br>

这个定义涵盖了连续、离散、或两者都有的随机变量。方差亦可当作是随机变量与自己本身的协方差(或协方差)：

<br>
$$
Var(X)=Cov(X,X)
\tag{4}
$$
<br>

方差典型的标记有$Var(X)$,$\sigma_x^2$，$\sigma^2$其表示式可展开成为：

<br>
$$
\begin{align}
Var(X)&=E[(X-E[X])^2]\\
&=E[X^2-2XE[X]+(E[X])^2]\\
&=E[X^2]-2E[X]E[X]+(E[X])^2\\
&=E[X^2]-(E[X])^2\\
\end{align}
\tag{5}
$$
<br>

上述的表示式可记为**"平方的期望减掉期望的平方"**。

---

#### 离散随机变量

如果随机变量*X*是具有概率质量函数的离散概率分布$x_1↦p_1,...,x_n↦p_n$，则：

<br>
$$
Var(X)=\sum\limits_{i=1}^n{p_i\cdot(x_i-\mu)^2}
=\sum\limits_{i=1}^n{(p_i\cdot x_i^2)-\mu^2}
\tag{6}
$$
<br>

此处$\mu$ 是其期望值, i.e.

<br>
$$
\mu=\sum\limits_{i=1}^n{p_i\cdot x_i}
\tag{7}
$$
<br>

当$X$为有$N$个相等概率值的平均分布：

<br>
$$
Var(X)=\frac{1}{N}\sum\limits_{i=1}^n{(x_i-\mu)^2}
=\frac{1}{N}\bigg(\sum\limits_{i=1}^n{x_i^2-N\mu^2\bigg)}
\tag{8}
$$
<br>

$N$个相等概率值的方差亦可以点对点间的方变量表示为：

<br>
$$
Var(X)=\frac{1}{N^2}\sum\limits_{i=1}^n{
\sum\limits_{j=1}^N{\frac{1}{2}(x_i-x_j)^2}
}
\tag{9}
$$

<br>

> 这里通过对比概率相同和概率不同，我们可以很好的来立即概率不同的情况相当于对于每一个随机变量对于均值的差*单独的概率

### 4、具体计算

**步骤：**

1. 先求数据的均值
2. 再求数据和均值差的平方
3. 最后除以数据的长度

```python
'''Sample Date - SH000300 Earning in 2017-03'''
datas = [0.16, -0.67, -0.21, 0.54, 0.22, -0.15, -0.63, 0.03, 0.88, -0.04, 0.20, 0.52, -1.03, 0.11, 0.49, -0.47, 0.35, 0.80, -0.33, -0.24, -0.13, -0.82, 0.56]
'''求均值'''
mean1 = sum(datas)/len(datas)  #result =  0.0060869565217391355
'''求方差'''
square_datas = []
for i in datas:
	square_datas.append((i-mean1)*(i-mean1))
variance = sum(square_datas)/len(square_datas)
print(str(variance))
# result = 0.25349338374291114
```



## 二、协方差

### 1、简单定义

> 如果有X,Y两个变量，每个时刻的“X值与其均值之差”乘以“Y值与其均值之差”得到一个乘积，再对这每时刻的乘积求和并求出均值，即为协方差。

### 2、实际意义

> 协方差（Covariance）在概率论和统计学中用于衡量两个变量的总体误差

### 3、公式定义

期望值分别为$E[X]$与$E[Y]$的两个实随机变量$X$与$Y$之间的**协方差***$Cov(X,Y)$定义为：

<br>
$$
\begin{align}
Cov(X,Y)&=E[(X-E[X])(Y-E[Y])]\\
&=E[XY]-2E[X]E[Y]+E[X]E[Y]\\
&=E[XY]-E[X]E[Y]\\
\end{align}
\tag{10}
$$
<br>

从直观上来看，协方差表示的是两个变量总体误差的期望。

如果两个变量的变化**趋势一致**，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是**正值**；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$E[XY]=E[X]E[Y]$。

但是，反过来并不成立。即如果X与Y的协方差为0，二者并不一定是统计独立的。

协方差$Cov(X,Y)$的度量单位是$X$的协方差乘以$Y$的协方差。而取决于协方差的相关性，是一个衡量线性独立的无量纲的数。

协方差为0的两个随机变量称为是不相关的。

### 4、具体计算

**步骤：**

1. 先求两个数据的均值
2. 再求数据和各自均值的差，然后相乘
3. 最后除以数据的长度

```python
import math
# Sample Date - SH000300 Earning in 2017-03

datas_sh000300 = [0.16, -0.67, -0.21, 0.54, 0.22, -0.15, -0.63, 0.03, 0.88, -0.04, 0.20, 0.52, -1.03, 0.11, 0.49, -0.47, 0.35, 0.80, -0.33, -0.24, -0.13, -0.82, 0.56]
datas_sz000651 = [0.07, -0.55, -0.04, 3.11, 0.28, -0.50, 1.10, 1.97, -0.31, -0.55, 2.06, -0.24, -1.44, 1.56, 3.69, 0.53, 2.30, 1.09, -2.63, 0.29, 1.30, -1.54, 3.19]
'''求均值'''
mean_sh000300 = sum(datas_sh000300) / len(datas_sh000300)
mean_sz000651 = sum(datas_sz000651) / len(datas_sz000651)
'''求协方差'''
temp_datas = []
for i in range(0, len(datas_sh000300)):
    temp_datas.append((datas_sh000300[i] - mean_sh000300) * (datas_sz000651[i] - mean_sz000651))
cov = sum(temp_datas)/len(temp_datas)

print(str(cov))
# result = 0.4385294896030246
```



## 三、协方差矩阵

分别为$m$ 与$n$ 个标量元素的列向量随机变量$X$ 与$Y$，二者对应的期望值分别为$μ$与$ν$，这两个变量之间的协方差定义为$m×n$矩阵

<br>
$$
cov(X,Y)=E((X-\mu)(Y-ν)^T)
\tag{11}
$$
<br>

两个向量变量的协方差$cov(X, Y)$与$cov(Y, X)$互为转置矩阵

协方差有时也称为是两个随机变量之间**“线性独立性”**的度量，但是这个含义与线性代数中严格的线性独立性线性独立不同。

## 参考文献

[协方差](https://wc.yooooo.us/d2lraS8lRTUlOEQlOEYlRTYlOTYlQjklRTUlQjclQUUhemg=)

[方差、标准差和协方差三者之间的定义与计算](https://www.cnblogs.com/xunziji/p/6772227.html)

